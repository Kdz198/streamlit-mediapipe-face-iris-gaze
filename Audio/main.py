import whisper
import warnings
import sounddevice as sd
from scipy.io.wavfile import write
import numpy as np
import re

# --- C·∫§U H√åNH ---
DURATION = 30  # Test 20s cho t·∫≠p trung
FS = 44100
FILENAME = "test_smart_logic.wav"
warnings.filterwarnings("ignore")


def record_audio(duration, filename):
    print(f"\nüé§ ƒêANG THU √ÇM TRONG {duration} GI√ÇY...")
    print("üëâ K·ªäCH B·∫¢N (C·ªë g·∫Øng ƒë·ªçc ƒë√∫ng nh·ªãp):")
    print("1. 'T√™n t√¥i l√† Nam.' (N√≥i li·ªÅn m·∫°ch - AI ph·∫£i tha)")
    print("2. 'T√™n t√¥i... (ngh·ªâ)... l√†... ·ªù... Nam.' (Ng·∫≠p ng·ª´ng - AI ph·∫£i b·∫Øt)")
    print("-" * 60)

    device_id = 0  # Ho·∫∑c ƒë·ªïi l·∫°i mic c·ªßa b·∫°n
    recording = sd.rec(int(duration * FS), samplerate=FS, channels=1, device=device_id)
    sd.wait()

    max_val = np.max(np.abs(recording))
    if max_val > 0: recording = recording / max_val * 0.9
    write(filename, FS, recording)
    print(f"‚úÖ ƒê√£ l∆∞u file.")


def analyze_smart_logic(audio_path):
    print(f"‚è≥ ƒêang t·∫£i Model 'MEDIUM' (V·ªõi Prompt 'b·∫©n')...")

    model = whisper.load_model("medium")

    # --- THAY ƒê·ªîI QUY·∫æT ƒê·ªäNH ·ªû ƒê√ÇY ---
    # Thay v√¨ ra l·ªánh, ta ƒë∆∞a v√≠ d·ª• c·ª• th·ªÉ ch·ª©a ƒë·∫ßy t·ª´ ƒë·ªám.
    # Model s·∫Ω nh√¨n v√†o ƒë√¢y v√† hi·ªÉu: "√Ä, phong c√°ch c·ªßa b√†i n√†y l√† ph·∫£i ghi c·∫£ ti·∫øng ·∫≠m ·ª´".
    dirty_prompt = "D·∫° th∆∞a... ·ªù... anh ch·ªã, em... √†... t√™n l√†... ·ª´m... Nguy·ªÖn VƒÉn A. Em... ·ªù... xin ph√©p... √†... tr√¨nh b√†y."

    result = model.transcribe(
        audio_path,
        language="vi",
        initial_prompt=dirty_prompt,  # D√πng prompt b·∫©n
        condition_on_previous_text=False,
        word_timestamps=True,
        # C√°c tham s·ªë gi√∫p model nh·∫°y h∆°n v·ªõi ti·∫øng ƒë·ªông l·∫°
        beam_size=5,
        best_of=5,
        temperature=0.2
    )

    print("\n" + "=" * 20 + " PH√ÇN T√çCH TH√îNG MINH " + "=" * 20)

    # M·ªü r·ªông t·ª´ ƒëi·ªÉn ƒë·ªÉ b·∫Øt d√≠nh h∆°n
    hard_fillers = ["·ªù", "√†", "·ª´m", "um", "hmm", "ha", "h·∫£", "ho", "ui", "uh"]
    soft_fillers = ["th√¨", "l√†", "m√†", "ki·ªÉu", "c√°i", "r·ªìi", "v·∫≠y"]

    detected_errors = []

    print("--- TRANSCRIPT CHI TI·∫æT ---")

    previous_end_time = 0.0

    for segment in result['segments']:
        line_buffer = ""
        for word_info in segment['words']:
            raw_word = word_info['word']
            # L√†m s·∫°ch nh·∫π nh√†ng h∆°n ƒë·ªÉ kh√¥ng m·∫•t d·∫•u v·∫øt
            clean_word = re.sub(r'[^\w]', '', raw_word).strip().lower()

            start = word_info['start']
            end = word_info['end']
            silence_gap = start - previous_end_time

            is_error = False
            error_type = ""

            # LOGIC 1: B·∫Øt Hard Filler (·ªú, √Ä, ·ª™m)
            if clean_word in hard_fillers:
                is_error = True
                error_type = "HARD"

            # LOGIC 2: B·∫Øt Soft Filler (Th√¨, L√† + Ng·∫≠p ng·ª´ng)
            # Gi·∫£m threshold xu·ªëng 0.3s ƒë·ªÉ nh·∫°y h∆°n
            elif clean_word in soft_fillers and silence_gap > 0.3:
                is_error = True
                error_type = f"SOFT(gap={silence_gap:.2f}s)"

            if is_error:
                line_buffer += f" [‚ùå{raw_word}] "
                detected_errors.append(f"'{raw_word}' ({error_type})")
            else:
                line_buffer += f"{raw_word} "

            previous_end_time = end

        print(line_buffer)

    print("\n" + "=" * 20 + " T·ªîNG K·∫æT " + "=" * 20)
    print(f"üìù Full Text: \n{result['text']}")
    print("-" * 50)
    print(f"üìä S·ªë l·ªói ph√°t hi·ªán: {len(detected_errors)}")
    if detected_errors:
        print(f"üîç Chi ti·∫øt: {detected_errors}")
    else:
        print("‚ö†Ô∏è V·∫´n kh√¥ng b·∫Øt ƒë∆∞·ª£c? -> H√£y th·ª≠ n√≥i '·ªú' v√† '·ª™m' to h∆°n v√† k√©o d√†i h∆°n.")


if __name__ == "__main__":
    record_audio(DURATION, FILENAME)
    analyze_smart_logic(FILENAME)